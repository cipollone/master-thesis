\chapter{Learning to valuate fluents in games}

The importance of correctly valuate the fluents.

\section{Temporal constraints}

How we can use temporal logic to express legal traces of interpretations;
e.g. expected behaviours.

\section{Assumptions}

A temporal constraints aren't definitions; they are just minimal constraints.
We need additional clues: visual description of fluents.
Now follow my assumptions:
\begin{itemize}
	\item Local propertes (with regions I don't have to find elements in a
		frame).
	\item The property is visually apparent, inside the region.
\end{itemize}

Limitations and other ideas for a stronger grouding.

\section{General structure of the model}

Illustration and general description of the model.

\section{Encoding}

Encoder: the model, how it works, what does it learn, size of the encoding.

References:
Training Restricted Boltzmann Machines and Deep Belief Neworks
\cite{bib:rbm-training}\cite{bib:ml-book-murphy}.

\subsection{Model: Deep Belief Network}

\subsection{What does it learn}


\section{Boolean functions}

The fluents are true in a set of those configurations.

\subsection{Learning with genetic algorithms}

Ideas from concept learning; genetic algorithm.

References:
Genetic Algorithms for Concept learning\cite{bib:ga-for-concepts},
Genetic Algorithms review\cite{bib:ga-mutations-review}.

\subsection{Boolean rules}

Representation of boolean functions and training details.
