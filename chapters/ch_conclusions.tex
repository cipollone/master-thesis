\chapter{Conclusions}

\label{ch:conclusions}

\section{Overview}

With this thesis, we addressed the problem of applying a method, called the
``Restraining Bolt''~\cite{bib:bolt}, to Deep Reinforcement learning. This
necessity is caused by the known limitations of RL, that Deep RL directly
inherits: the Markovian assumptions on rewards an observations. Full
observability, in particular, is always falsified in the real world, and even
in some video games of moderate complexity. Instead, this logic construction,
inspired by~\cite{bib:nmrdp-logic-first}, allowed us to solve RL environments
with sparse rewards, and a large class of tasks with partial observations and
non-Markovian goals. This means that we're starting to address the group of
problems where RL and Deep RL always struggled.

However, any form of logic reasoning works by manipulating an abstraction. In
the case of the temporal logics used by Restraining Bolt, we're talking about
a set of atomic propositions, that represent the state of some meaningful
conditions in the outside world. Creating this connection, between environment
observations and true atomic propositions, is clearly not an easy task. The
more complex the observations become, the harder is to \emph{ground} the truth
of such symbols to the environment states. This is the major limitation that
impede the application of some high-level reasoning to Deep RL.

By slightly extending the concepts of ``observation'' and ``proposition'',
any decision problem can be stated as the issue addressed here: the problem of
deciding the truth of a propositional atom. So, after the general frame in
which this problem has been introduced, we must remember that we've only
considered a limited class of observations and propositions.

Our observations are images of the video games of the collection Atari~2600.
Propositions are conditions on visual features on the image, such as the
presence of an object at some location, or a certain pattern of a visible
feature. Limitations and assumptions regarding propositions have been listed
thorough Chapter~\ref{ch:fluents}.
\enlargethispage{1\baselineskip}


\section{Main contributions}

In this section, we summarize the main contributions of this thesis. Most of
them have been motivated by the need of a successful application of the
Restraining Bolt to Deep Reinforcement Learning. The Restraining Bolt has been
previously demonstrated only in combination with RL. Moving to more complex
observations required to devise many original solutions that we list here:

\begin{description}[style=nextline]
	
	\item[Model for a deep restrained agent]
		Deep RL agents trained with value-based algorithms rely on Q-Networks.
		When the agent plays in combination with a Restraining Bolt, it receives
		the image from the environment and the RB state. How should be combine
		such different inputs in the agent's network? The model proposed in
		Section~\ref{sec:model-atari-rb} uses the RB state to select the
		appropriate parameters to use among a set. Although only a portion of the
		network has been separated, this allow to produce radically different
		policies for distinct RB states.

	\item[Learning fluents with temporal constraints]
		Chapter~\ref{ch:fluents} proposed original ideas to solve the problem of
		learning valuations for some propositions. We used formulae of temporal
		logics to express the expected temporal behaviour of the desired
		valuations. The known limitations of this approach have been discussed in
		Section~\ref{sec:fluents-limitations}, but we also provided experiments to
		shown that these ideas can be effective in the class of problems under
		consideration.

	\item[Models for the features extractor]
		With ``features extractor'' we called the complete function that from an
		image of the game returns the fluents Boolean values. This thesis also
		proposed a model for this function, which combines a part of unsupervised
		learning, a DBN network, and an array of Boolean functions. This last part
		is inspired by the area of concept learning. This double arrangement
		addresses the known limitations of temporal constraints.  Furthermore, as
		the visualizations in the Experiments chapter have shown, the output
		encoding of the DBN can be understood by the human observer.  The final
		part of the model might also be easily be defined by hand, if we desire.

	\item[The \texttt{atarieyes} package]
		We provide an implementation for all the ideas presented in this thesis.
		The software \texttt{atarieyes} is a Python package, documented in a clear
		way.  Most operations can be performed just from the command line
		interface it provides, with many tunable training parameters. Its internal
		structures can be also adopted in future applications, thanks to the
		modular design of the package. The most interesting feature is that the
		functionalities related to the fluents are completely separated from the
		RL agent. We could even train a feature extractor or apply the Restraining
		Bolt with agents realized with other Deep RL libraries.

\end{description}

We conclude with two minor contributions that are worth mentioning. First, we
worked to the recent improvements to the \texttt{flloat} Python library,
together with the original author~\cite{bib:favorito-thesis}. This is package
is currently used by researchers for \ldl{}-to-DFA translations, and it's the
one we adopted in this thesis. Together, we worked for a more stable version
of the software and an improved language parser for \ldl{}.

Lastly, we'd like to emphasize that Chapter~\ref{ch:nonmarkovrl} presented RL
problems with partial observations and temporally extended goals, with a
unified approach. We've shown some similarities between the two, and started
to illustrate why it is possible to adopt the Restraining Bolt, which is
devised for the latter group, also for some problems of the former class.
We've discussed that if it can be successfully applied, the RB is a clever way
to define the extended state space which include the relevant history-related
informations.


\section{Future works}

\label{sec:future}

Features extraction is clearly a central topic of this work. We believe that
temporal logics can be also used to describe the desired meaning of our
symbols. Still, we don't think to have satisfactorily demonstrated this
possibility. In the future, we'd like to remove some of the most limiting
assumptions taken in this thesis, so to allow more interesting possibilities.
Aware of the current limitations of this work, we conclude the thesis by
suggesting some interesting directions for future research:
\begin{description}
	\item [Removing regions]
		One simplification we took is valuating fluents on fixed portions of the
		input image. Clearly, this strongly restricts the class of observations
		that can be handled, since it requires mostly static elements in the
		scene.  We should definitely avoid this. One possibility is to define
		regions not on fixed locations, but on specific visual features of the
		image. The idea is first to find the relevant feature, then evaluate the
		symbol on a portion of the input at that moving position.

	\item [Removing metrics]
		The ``consistency'' and ``sensitivity'' metrics have been used to rank
		candidate function and pick a solution. However, both of them induce a
		rather arbitrary ordering over candidates, which might not suitable for
		all problems. They are a form of heuristics, biasing our search. Instead,
		we should only check for satisfaction between the traces and the
		constraint.  The reason for their adoption is that, as we've discussed in
		Section~\ref{sec:fluents-limitations}, temporal constraints are very weak
		indications when used alone. We should search alternative and more correct
		ways to \emph{ground} the model predictions to the desired valuations.

	\item [Strong grounding]
		We believe that this last issue is the most important to discuss. Temporal
		constraints are just weak indications of the desired input-output
		associations. Just by talking in some abstract language, we can't hope to
		reliably bind the abstraction we're using to the external world states.
		These states must appear inside the specification, somehow. We propose to
		investigate two possibilities:
		\begin{itemize}
			\item The first is to include in the temporal specification some
				\emph{grounded} fluents. Grounded fluents are propositional symbols
				which are exactly valuated. They might come from events that the
				agent already knows, such as the action just performed, or from
				conditions reliably valuated by some ad-hoc Neural Network.
			\item The second is to include a very small dataset of few input-output
				labelled samples. These very few examples can specify desired
				valuations which would be hard to describe otherwise.
		\end{itemize}
		We strongly believe that merging temporal constraints with more classic
		sources of informations like the two mentioned above would create very
		more specific and effective descriptions of the desired concepts.

	\item [Experiments] The last, and more obvious, necessity is to test 
		these improvements to see what can be achieved. We believe that these
		changes would open many possibilities. Also the original idea hasn't been
		satisfactorily demonstrated just from the experiments shown in this
		thesis.
\end{description}

The problem we tried to addressed in this work is a central topic. This isn't
something related just to the Restraining Bolt method, but with any form of
logic reasoning on Deep RL agents. Even in presence of a Markovian task, which
might be solved with a pure Deep RL agent, there might be the necessity to
look into the agent policy. Policies on images are really hard to visualize
and understand, because they don't process structured representations, which
are much clearer for humans. Being able to create reliable abstractions is an
important goal that would also help to us to better understand the agent's
purposes and strategies.
